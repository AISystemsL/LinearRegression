# LinearRegression
Example of Linear regression, using gradient descent algorithm.  
Just basic example with 1-dimension input and 1-dimension output, and only two weights / free parameters. η (eta) hyperparameter: step size / learning rate.  
With Loss function using Tikhonov regularization (with hyperparameter λ (lambda)).  
Graph plotting (with sympy or matplotlib) of the Error(w) and Loss(w) over time (learning steps/epochs).  

ToDo:  
Extend to general n weights and n input dimensions (vector and matrix products using numpy)  
Add linear basis expansion (LBE)  
